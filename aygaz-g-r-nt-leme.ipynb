{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2333429,"sourceType":"datasetVersion","datasetId":1408532}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n**AYGAZ GÖRÜNTÜ İŞLEME PROJESİ**\n\n**Hayvan Sınıflandırma İçin CNN Modeli**\n\n\n**Proje Özeti**\nBu projenin amacı, Konvolüsiyonel Sinir Ağlarının (CNN) temelini anlamak ve hayvan resimlerini sınıflandırmak için bir model oluşturmaktır. Proje, bir CNN modeli eğitme, çeşitli koşullarda test etme ve performansını analiz etmeyi kapsamaktadır. Ayrıca, görüntü manipülasyonu ve renk sabitleme gibi teknikler de uygulanmaktadır.\n\n1.\t**Veri Seti**\nBu projede kullanılan veri seti, \"Animals with Attributes 2\" adlı veri setidir. Veri setine [Kaggle](https://www.kaggle.com/datasets/rrebirrth/animals-with-attributes-2) üzerinden erişebilirsiniz. Kullanılan resimler `JPEGImages` klasöründe yer almaktadır.\nModel, aşağıdaki on hayvan sınıfını sınıflandıracak şekilde tasarlanmıştır:\n\n\n\t* Collie\n\t* Dolphin\n    * Elephant\n    * Fox\n    * Moose\n    * Rabbit\n    * Sheep\n    * Squirrel\n    * Giant Panda\n    * Polar Bear\n\n**Gerekli Kütüphaneler Hakkında Bilgi**\n* **os:** Dosya ve dizin işlemleri yapmanızı sağlar. Örneğin, dosya yolu birleştirme ve dizin listeleme.\n* **shutil:** Dosya ve dizinleri kopyalamak, taşımak ve silmek için kullanılır.\n* **cv2 (OpenCV):** Görüntü işleme için kullanılır, resimleri okuma, boyutlandırma, kenar tespiti gibi işlemler yapar.\n* **numpy (np):** Matematiksel işlemler ve büyük veri setleriyle çalışmak için kullanılan bir kütüphanedir.\n* **sklearn.model_selection.train_test_split:** Veriyi eğitim ve test setlerine ayırmak için kullanılır.\n* **tensorflow.keras.models.Sequential:** Katmanları sırasıyla ekleyerek derin öğrenme modeli oluşturmanıza olanak tanır.\n* **tensorflow.keras.layers.Conv2D:** Görüntülerdeki özellikleri öğrenmek için konvolüsyonel katman ekler.\n* **tensorflow.keras.layers.MaxPooling2D:** Görüntülerin boyutlarını küçültür ve önemli özelliklerin korunmasını sağlar.\n* **tensorflow.keras.layers.Flatten:** Çok boyutlu veriyi tek boyutlu hale getirir.\n* **tensorflow.keras.layers.Dense:** Tam bağlantılı katman ekler ve modelin karar verme kısmını oluşturur.\n* **tensorflow.keras.layers.Dropout:** Aşırı uyumu (overfitting) engellemek için bazı nöronları rastgele sıfırlar.\n* **tensorflow.keras.layers.Input:** Modelin giriş boyutunu tanımlar.\n* **tensorflow.keras.preprocessing.image.ImageDataGenerator:** Veri artırma (augmentation) işlemleri yaparak eğitim verisini çeşitlendirir.\n* **tensorflow.keras.optimizers.Adam:** Eğitim sırasında modelin parametrelerini optimize etmek için kullanılan bir algoritmadır.\n* **sklearn.metrics.classification_report:** Modelin performansını doğruluk, precision, recall gibi metriklerle özetler.\n* **sklearn.metrics.confusion_matrix:** Modelin doğru ve yanlış sınıflandırmalarını görselleştiren bir matris oluşturur.\n* **seaborn (sns):** İstatistiksel veriyi görselleştirmek için kullanılan bir grafik kütüphanesidir.\n* **matplotlib.pyplot (plt):** Grafikler ve çizimler oluşturmak için kullanılan bir kütüphanedir.\n* **sklearn.preprocessing.OneHotEncoder:** Kategorik verileri sayısal verilere dönüştürür, her sınıf için ikili vektörler oluşturur.\n\n","metadata":{}},{"cell_type":"code","source":"#Gerekli kütüphaneler\nimport os\nimport shutil\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:16:00.862507Z","iopub.execute_input":"2024-12-22T20:16:00.862841Z","iopub.status.idle":"2024-12-22T20:16:09.622514Z","shell.execute_reply.started":"2024-12-22T20:16:00.862812Z","shell.execute_reply":"2024-12-22T20:16:09.621674Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"**Verinin Yüklenmesi ve Filtrelenmesi**\n10 sınıfa ait görsellerin bulunduğu klasörler belirlenir ve yalnızca seçilen sınıflara ait görüntülerin bulunduğu klasörler başka klasöre kopyalanır. Ayrıca her sınıf için yalnızca ilk 650 görüntü saklanır, bu sayede veri setinin boyutu dengelenmiş olur.","metadata":{}},{"cell_type":"code","source":"# JPEGImages klasörü\ndata_dir = \"/kaggle/input/animals-with-attributes-2/Animals_with_Attributes2/JPEGImages\"\n\n# Sınıfları listeleme\nclasses = os.listdir(data_dir)\nprint(f\"Toplam sınıf sayısı: {len(classes)}\")\nprint(\"Sınıflar:\")\nprint(classes)\n\n# Filtrelenen veri setinin saklanacağı klasör\nfiltered_dir = \"/kaggle/working/filtered_animals\"\nos.makedirs(filtered_dir, exist_ok=True)\n\n# Kullanılacak sınıflar\nselected_classes = ['collie', 'dolphin', 'elephant', 'fox', 'moose', 'rabbit', 'sheep', 'squirrel', 'giant+panda', 'polar+bear']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:16:09.623747Z","iopub.execute_input":"2024-12-22T20:16:09.624258Z","iopub.status.idle":"2024-12-22T20:16:09.638231Z","shell.execute_reply.started":"2024-12-22T20:16:09.624215Z","shell.execute_reply":"2024-12-22T20:16:09.637407Z"}},"outputs":[{"name":"stdout","text":"Toplam sınıf sayısı: 50\nSınıflar:\n['fox', 'wolf', 'horse', 'antelope', 'hamster', 'skunk', 'chimpanzee', 'lion', 'otter', 'giant+panda', 'raccoon', 'hippopotamus', 'bobcat', 'pig', 'rat', 'spider+monkey', 'buffalo', 'mouse', 'tiger', 'bat', 'grizzly+bear', 'gorilla', 'dalmatian', 'killer+whale', 'siamese+cat', 'humpback+whale', 'chihuahua', 'beaver', 'polar+bear', 'german+shepherd', 'elephant', 'sheep', 'collie', 'moose', 'zebra', 'seal', 'cow', 'ox', 'mole', 'rabbit', 'giraffe', 'persian+cat', 'rhinoceros', 'dolphin', 'blue+whale', 'squirrel', 'leopard', 'deer', 'weasel', 'walrus']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#Sadece gerekli olan sınıfları kopyalayarak yeni bir klasör oluşturuyoruz.\n\nfor class_name in selected_classes:\n    source_path = os.path.join(data_dir, class_name)\n    target_path = os.path.join(filtered_dir, class_name)\n    if os.path.exists(source_path):\n        shutil.copytree(source_path, target_path)\n        print(f\"{class_name} sınıfı kopyalandı.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:16:09.639979Z","iopub.execute_input":"2024-12-22T20:16:09.640268Z","iopub.status.idle":"2024-12-22T20:17:31.274120Z","shell.execute_reply.started":"2024-12-22T20:16:09.640222Z","shell.execute_reply":"2024-12-22T20:17:31.272849Z"}},"outputs":[{"name":"stdout","text":"collie sınıfı kopyalandı.\ndolphin sınıfı kopyalandı.\nelephant sınıfı kopyalandı.\nfox sınıfı kopyalandı.\nmoose sınıfı kopyalandı.\nrabbit sınıfı kopyalandı.\nsheep sınıfı kopyalandı.\nsquirrel sınıfı kopyalandı.\ngiant+panda sınıfı kopyalandı.\npolar+bear sınıfı kopyalandı.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#Resim sayısını dengelemek için her sınıftan yalnızca ilk 650 resmi saklıyoruz.\nfor class_name in selected_classes:\n    class_path = os.path.join(filtered_dir, class_name)\n    images = sorted(os.listdir(class_path))  # Alfabetik sıraya göre sıralama\n    for image in images[650:]:  # İlk 650 resmi tut\n        os.remove(os.path.join(class_path, image))\n    print(f\"{class_name} sınıfından yalnızca ilk 650 resim tutuldu.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:17:31.275937Z","iopub.execute_input":"2024-12-22T20:17:31.276281Z","iopub.status.idle":"2024-12-22T20:17:31.760351Z","shell.execute_reply.started":"2024-12-22T20:17:31.276221Z","shell.execute_reply":"2024-12-22T20:17:31.758484Z"}},"outputs":[{"name":"stdout","text":"collie sınıfından yalnızca ilk 650 resim tutuldu.\ndolphin sınıfından yalnızca ilk 650 resim tutuldu.\nelephant sınıfından yalnızca ilk 650 resim tutuldu.\nfox sınıfından yalnızca ilk 650 resim tutuldu.\nmoose sınıfından yalnızca ilk 650 resim tutuldu.\nrabbit sınıfından yalnızca ilk 650 resim tutuldu.\nsheep sınıfından yalnızca ilk 650 resim tutuldu.\nsquirrel sınıfından yalnızca ilk 650 resim tutuldu.\ngiant+panda sınıfından yalnızca ilk 650 resim tutuldu.\npolar+bear sınıfından yalnızca ilk 650 resim tutuldu.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Etiketler ve Resimler İçin Listeler Oluşturulması\nBu bölümde, görsellerin ve etiketlerin listelendiği ve işlenmeye hazır hale getirildiği adımlar yer almaktadır.\n\n1. **Boş listeler oluşturuluyor**:\n   - `X` listesi, görselleri depolamak için kullanılır.\n   - `y` listesi, her bir görselin etiketini (sınıf ismi) saklamak için kullanılır.\n\n2. **Her sınıf için resimler okunuyor**:\n   - `os.listdir(filtered_dir)` komutu ile `filtered_dir` dizinindeki tüm alt dizinler (sınıflar) liste haline getirilir.\n   - Her bir sınıf için, o sınıfa ait resimler `cv2.imread` ile okunur.\n   - Görseller, `cv2.resize(img, (128, 128))` fonksiyonu ile 128x128 piksel boyutuna yeniden boyutlandırılır.\n   - Görsellerin değerleri `[0, 1]` aralığına normalize edilir (`img_normalized = img_resized / 255.0`).\n   - Görsel ve etiketler sırasıyla `X` ve `y` listelerine eklenir.\n\n3. **X ve y NumPy Dizilerine Dönüştürülür**:\n   - `X` ve `y` listeleri NumPy dizilerine dönüştürülür (`np.array(X)` ve `np.array(y)`).\n\n4. **Eğitim ve Test Verilerine Ayırma**:\n   - `train_test_split` fonksiyonu ile veriler eğitim ve test setlerine ayrılır. Bu işlemde:\n     - `test_size=0.2` ile verilerin %20'si test verisi olarak ayrılır.\n     - `random_state=42` parametresi, her çalıştırmada aynı sonuçların elde edilmesini sağlar.\n   - Eğitim seti ve test setinin boyutları yazdırılır.\n\nSonuç olarak, bu kod, veri setini eğitim ve test setlerine ayırarak derin öğrenme modelini eğitmek için kullanılabilir hale getirir.","metadata":{}},{"cell_type":"code","source":"# Etiketler ve resimler için listeler\nX = []  # Görüntü verisi\ny = []  # Etiketler (sınıflar)\n\n# Her sınıf için resimleri oku\nfor class_name in os.listdir(filtered_dir):\n    class_path = os.path.join(filtered_dir, class_name)\n    if os.path.isdir(class_path):\n        for image_name in os.listdir(class_path):\n            image_path = os.path.join(class_path, image_name)\n            img = cv2.imread(image_path)\n            if img is not None:\n                img_resized = cv2.resize(img, (128, 128))  # Görüntüyü yeniden boyutlandır\n                img_normalized = img_resized / 255.0  # Normalize et\n                X.append(img_normalized)\n                y.append(class_name)  # Etiket olarak sınıf ismini kullan\n\n# X ve y numpy dizilerine dönüştürülüyor\nX = np.array(X)\ny = np.array(y)\n\n# Eğitim ve test verilerini ayırma (80% eğitim, 20% test)\n# X: images, y: labels anlamına gelmektedir\n# random_state=42 her çalıştırmada aynı sonuçları almamızı sağlar.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"Eğitim verisi boyutu: {X_train.shape}\")\nprint(f\"Test verisi boyutu: {X_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:17:31.761640Z","iopub.execute_input":"2024-12-22T20:17:31.762037Z","iopub.status.idle":"2024-12-22T20:18:40.029552Z","shell.execute_reply.started":"2024-12-22T20:17:31.761996Z","shell.execute_reply":"2024-12-22T20:18:40.027816Z"}},"outputs":[{"name":"stdout","text":"Eğitim verisi boyutu: (5200, 128, 128, 3)\nTest verisi boyutu: (1300, 128, 128, 3)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Aşağıdaki kod, görüntü işleme ve etiket dönüştürme işlemleri gerçekleştirir. İlk olarak, ImageDataGenerator sınıfı ile veri artırma işlemleri yapılır; bu işlemler arasında döndürme, kaydırma, yakınlaştırma ve yatay çevirme gibi teknikler bulunur. Bu sayede modelin genelleme yeteneği artırılır. Ayrıca, özel bir custom_augmentation fonksiyonu ile görüntülere bulanıklaştırma ve kenar bulma gibi manipülasyonlar uygulanabilir. Son olarak, etiketler, OneHotEncoder kullanılarak sayısal vektörlere dönüştürülür, bu da modelin sınıflandırma işlemi için gereklidir. Bu adımlar, modelin eğitim verisi üzerinde daha iyi performans göstermesine yardımcı olur.","metadata":{}},{"cell_type":"code","source":"# Veri artırma işlemleri için ImageDataGenerator oluşturma\ndatagen = ImageDataGenerator(\n    rotation_range=20,         # Görüntüleri rastgele döndürme\n    width_shift_range=0.1,     # Yatayda kaydırma\n    height_shift_range=0.1,    # Dikeyde kaydırma\n    shear_range=0.2,           # Kesme dönüşümü\n    zoom_range=0.2,            # Yakınlaştırma\n    horizontal_flip=True,      # Yatayda çevirme\n    fill_mode='nearest',       # Boş alanları doldurmak için 'nearest' (yakın olan değeri kullanma)\n    rescale=1./255             # Görüntüleri normalize etme (0-255 arası değerleri 0-1 arası normalize eder)\n)\n\n# Özelleştirilmiş veri artırma fonksiyonu\ndef custom_augmentation(img):\n    # Bulanıklaştırma\n    blurred_img = cv2.GaussianBlur(img, (3, 3), 0)\n    \n    # Kenar bulma (Canny Edge Detection)\n    edge_img = cv2.Canny(blurred_img, 100, 200)\n\n# Etiketleri sayısal değerlere dönüştürme\n# OneHotEncoder oluştur\none_hot_encoder = OneHotEncoder(sparse_output=False)  # sparse_output=False ile dönen vektör numpy array olur\n\n# Eğitim ve test etiketlerini dönüştür\ny_train_encoded = one_hot_encoder.fit_transform(np.array(y_train).reshape(-1, 1))\ny_test_encoded = one_hot_encoder.transform(np.array(y_test).reshape(-1, 1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:22:15.884717Z","iopub.execute_input":"2024-12-22T20:22:15.885077Z","iopub.status.idle":"2024-12-22T20:22:15.899592Z","shell.execute_reply.started":"2024-12-22T20:22:15.885050Z","shell.execute_reply":"2024-12-22T20:22:15.898601Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Bu kod, bir konvolüsyonel sinir ağı (CNN) modeli oluşturur ve eğitir. Model, 128x128 boyutlarında 3 kanallı görüntüleri alacak şekilde yapılandırılmıştır. İlk iki katmanda, her biri Conv2D ile filtre uygulayan ve ardından MaxPooling2D ile boyutlarını küçülten katmanlar bulunur. Ardından, Flatten katmanı ile veriler tek boyutlu hale getirilir ve Dense katmanında 128 nöronlu bir tam bağlantılı katman kullanılır. Son katmanda, sınıf sayısına göre softmax aktivasyon fonksiyonu ile çok sınıflı sınıflandırma yapılır. Model, Adam optimizasyon algoritması ve categorical_crossentropy kayıp fonksiyonu ile derlenir. Eğitim sırasında, veri artırma teknikleri kullanılarak modelin genelleme yeteneği artırılır ve model 10 epoch boyunca eğitilir, ardından doğrulama verisi ile test edilir.","metadata":{}},{"cell_type":"code","source":"# CNN Modeli tanımlama\nmodel = Sequential([\n    Input(shape=(128, 128, 3)),  # Input katmanını ekledik\n    Conv2D(32, (3, 3), activation='relu'),  \n    MaxPooling2D(pool_size=(2, 2)),\n      \n    Conv2D(64, (3, 3), activation='relu'), \n    MaxPooling2D(pool_size=(2, 2)),\n      \n    Flatten(),\n    Dense(128, activation='relu'),  \n    Dropout(0.3),  \n    Dense(len(np.unique(y)), activation='softmax')  # Çıkış katmanı, sınıf sayısına göre softmax\n])\n\n# Belirli bir öğrenme oranı ile Adam optimizer kullanmak\nlearning_rate = 0.001  # İstediğimiz öğrenme oranını buraya yazabiliriz\noptimizer = Adam(learning_rate=learning_rate)\n\n# Modeli derleme\n\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Eğitim verisini kullanarak veri artırma uygulama\ndatagen.fit(X_train)\n\n# Veri artırma işlemi sırasında, görüntüleri sadece eğitim verisine uygulayacağız.\n\n# Modeli eğitme\nhistory = model.fit(\n    datagen.flow(X_train, y_train_encoded, batch_size=32),  # y_train_encoded kullanıyoruz\n    epochs=10,\n    validation_data=(X_test, y_test_encoded)  # y_test_encoded kullanıyoruz \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:25:35.098298Z","iopub.execute_input":"2024-12-22T20:25:35.098676Z","iopub.status.idle":"2024-12-22T20:37:20.873163Z","shell.execute_reply.started":"2024-12-22T20:25:35.098645Z","shell.execute_reply":"2024-12-22T20:37:20.871946Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 435ms/step - accuracy: 0.1035 - loss: 2.3031 - val_accuracy: 0.0908 - val_loss: 19.2113\nEpoch 2/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 473ms/step - accuracy: 0.0976 - loss: 2.3026 - val_accuracy: 0.0908 - val_loss: 19.3779\nEpoch 3/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 423ms/step - accuracy: 0.1065 - loss: 2.3025 - val_accuracy: 0.0908 - val_loss: 19.5247\nEpoch 4/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 416ms/step - accuracy: 0.0898 - loss: 2.3027 - val_accuracy: 0.0908 - val_loss: 19.5348\nEpoch 5/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 422ms/step - accuracy: 0.0989 - loss: 2.3024 - val_accuracy: 0.0908 - val_loss: 19.4484\nEpoch 6/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 421ms/step - accuracy: 0.0978 - loss: 2.3029 - val_accuracy: 0.0908 - val_loss: 19.6306\nEpoch 7/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 414ms/step - accuracy: 0.1033 - loss: 2.3024 - val_accuracy: 0.0908 - val_loss: 19.8128\nEpoch 8/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 420ms/step - accuracy: 0.1000 - loss: 2.3026 - val_accuracy: 0.0908 - val_loss: 19.7356\nEpoch 9/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 414ms/step - accuracy: 0.0950 - loss: 2.3029 - val_accuracy: 0.0908 - val_loss: 19.6928\nEpoch 10/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 414ms/step - accuracy: 0.0986 - loss: 2.3026 - val_accuracy: 0.0908 - val_loss: 19.7034\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Yukarıdaki çıktılar, modelin öğreniminde ciddi sorunlar olduğunu ve modelin doğru şekilde öğrenemediğini gösteriyor.\n-Eğitim doğruluğu (accuracy) her epoch boyunca %10 civarında ve artmıyor.\n-Eğitim kaybı (loss) ise yaklaşık 2.302'de sabit kalmış durumda.\n-Doğrulama doğruluğu (val_accuracy) da her epoch boyunca %9 civarında ve sabit.\n-Doğrulama kaybı (val_loss) ise aşırı yüksek (örneğin, 19.2113'ten başlayarak artmaya devam ediyor).\nBu durum, modelin sınıflandırma yapmayı öğrenemediğini ve rastgele tahminler yaptığını gösterir. y_train_encoded veya y_test_encoded doğru bir şekilde kategorik hale getirilmemiş olabilir. OneHotEncoder doğru uygulanmamış olabilir. X_train ve X_test verileri uygun şekilde normalize edilmemiş olabilir (örneğin, tüm piksel değerlerinin [0, 1] aralığına getirilmesi gerekiyor).","metadata":{}},{"cell_type":"code","source":"# Modelin test edilmesi\nresults = model.evaluate(X_test, y_test_encoded, verbose=1)\nprint(f\"Test kaybı: {results[0]}\")\nprint(f\"Test doğruluğu: {results[1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:37:28.235859Z","iopub.execute_input":"2024-12-22T20:37:28.236279Z","iopub.status.idle":"2024-12-22T20:37:32.982626Z","shell.execute_reply.started":"2024-12-22T20:37:28.236229Z","shell.execute_reply":"2024-12-22T20:37:32.981744Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.0962 - loss: 19.4738\nTest kaybı: 19.703445434570312\nTest doğruluğu: 0.09076923131942749\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Yukarıdaki çıktı, modelin test veri seti üzerinde de öğrenemediğini ve sınıflandırma performansının rastgele tahminden farksız olduğunu gösteriyor.","metadata":{}},{"cell_type":"code","source":"# Manipüle edilmiş görüntüler oluşturma\ndef get_manipulated_images(images):\n    manipulated_images = []\n    for img in images:\n        brightness_factor = np.random.uniform(0.5, 1.5)\n        manipulated_img = np.clip(img * brightness_factor, 0, 1)  # Parlaklık değişimi\n        manipulated_images.append(manipulated_img)\n    return np.array(manipulated_images)\n\n# Manipüle edilmiş test seti\nX_test_manipulated = get_manipulated_images(X_test)\n\n# Manipüle edilmiş set ile model testi\nmanipulated_results = model.evaluate(X_test_manipulated, y_test_encoded, verbose=1)\nprint(f\"Manipüle edilmiş test kaybı: {manipulated_results[0]}\")\nprint(f\"Manipüle edilmiş test doğruluğu: {manipulated_results[1]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:37:33.805112Z","iopub.execute_input":"2024-12-22T20:37:33.805487Z","iopub.status.idle":"2024-12-22T20:37:39.971198Z","shell.execute_reply.started":"2024-12-22T20:37:33.805458Z","shell.execute_reply":"2024-12-22T20:37:39.970133Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.0962 - loss: 19.0088\nManipüle edilmiş test kaybı: 19.265670776367188\nManipüle edilmiş test doğruluğu: 0.09076923131942749\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Bu sonuç, modelin manipüle edilmiş (örneğin, parlaklık değişimi uygulanmış) görüntüler üzerinde de kötü performans gösterdiğini, öğrenme başarısızlığının manipülasyonlarla iyileşmediğini gösteriyor. Normal test doğruluğu ile aynı (%9 civarında). Bu, modelin manipüle edilmiş görüntülerde de rastgele tahmin düzeyinde olduğunu ve manipülasyonların modeli geliştirmediğini doğruluyor.","metadata":{}},{"cell_type":"code","source":"# Renk sabitliği (Gray World algoritması)\ndef get_wb_images(images):\n    wb_images = []\n    for img in images:\n        avg_color = np.mean(img, axis=(0, 1))\n        wb_img = np.clip(img * (np.mean(avg_color) / avg_color), 0, 1)  # Normalize et\n        wb_images.append(wb_img)\n    return np.array(wb_images)\n\n# Renk sabitliği uygulanmış test seti\nX_test_wb = get_wb_images(X_test_manipulated)\n\n# Renk sabitliği uygulanmış set ile model testi\nwb_results = model.evaluate(X_test_wb, y_test_encoded, verbose=1)\nprint(f\"Renk sabitliği uygulanmış test kaybı: {wb_results[0]}\")\nprint(f\"Renk sabitliği uygulanmış test doğruluğu: {wb_results[1]}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:37:44.876845Z","iopub.execute_input":"2024-12-22T20:37:44.877267Z","iopub.status.idle":"2024-12-22T20:37:51.583122Z","shell.execute_reply.started":"2024-12-22T20:37:44.877213Z","shell.execute_reply":"2024-12-22T20:37:51.581757Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.0962 - loss: 24.4342\nRenk sabitliği uygulanmış test kaybı: 24.637224197387695\nRenk sabitliği uygulanmış test doğruluğu: 0.09076923131942749\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Bu sonuç, renk sabitliği (Gray World algoritması) uygulanmış veri üzerinde modelin performansının yine oldukça kötü olduğunu, test kaybının arttığını ve doğruluğun rastgele tahmin seviyesinde (%9) kaldığını gösteriyor. \n\n24.6372 -> Bu değer, hem orijinal test kaybı (19.7034) hem de manipüle edilmiş test kaybından (19.2656) daha yüksek. Bu, renk sabitliğinin modele zarar verdiğini ve öğrenmeyi daha da kötüleştirdiğini gösteriyor.\n","metadata":{}},{"cell_type":"markdown","source":"**Sonuçların Karşılaştırması**\n\n                             \n**Orijinal Test Seti ->**\t           Test Kaybı (Loss): 19.7034\t     Test Doğruluğu (Accuracy): 0.0907 (%9)\n**Manipüle Edilmiş Test Seti ->**\t   Test Kaybı (Loss): 19.2656\t     Test Doğruluğu (Accuracy): 0.0907 (%9)\n**Renk Sabitliği Test Seti  ->**\t   Test Kaybı (Loss): 24.6372\t     Test Doğruluğu (Accuracy): 0.0907 (%9)\n\n**Karşılaştırma ve Yorum**\n\n*Doğruluk:*\n\nÜç test durumunda da doğruluk %9 seviyesinde ve bu, modelin sınıfları rastgele tahmin ettiğini gösteriyor. Yani model sınıflar arasındaki özellikleri öğrenememiş.\n\n*Kaybın (Loss) Değişimi:*\n\nManipüle edilmiş görüntülerde kayıp bir miktar düşmüş olsa da bu, doğruluğa yansımamış. Renk sabitliği uygulandığında ise kayıp önemli ölçüde artmış.\nBu durum, manipülasyon ve renk sabitliği uygulamalarının modelin öğrenme yeteneğini daha da zayıflattığını gösteriyor.\n\n*Genel Performans:*\n\nModel, herhangi bir veri setinde işe yarar bir şekilde öğrenememiş. Hem eğitim sırasında hem de testlerde başarısız sonuçlar alınmış.\n\n**Çözüm önerileri:**\n\n- Hiperparametre ayarı yapabiliriz.\n- Transfer Learning Kullanabiliriz.\n- Model mimarisini geliştirebiliriz.","metadata":{}}]}